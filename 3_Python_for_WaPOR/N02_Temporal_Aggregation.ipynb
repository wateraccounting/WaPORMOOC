{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Using Python libraries for Handling WaPOR Data**\n",
        "#Notebook 2 : Temporal data aggregation\n",
        "\n",
        "In this Notebook we will show you how to do temporal aggregation of WaPOR data.  \n",
        "\n",
        "The steps we are going to follow are:\n",
        "1. Install and load necessary packages to manage rasterfiles\n",
        "2. Load the .zip file from Download_WaPORv3_data Notebook to this session (or create a new .zip)\n",
        "3. Unzip the files\n",
        "4. Open and inspect one .tif file\n",
        ">+Exercise 1 (answers needed for the MOOC quiz)\n",
        "5. Perform the temporal aggregation (sum) of the decadal ET & export result to local drive\n",
        ">+Exercise 2 (answers needed for the MOOC quiz)\n",
        "6. More detailed temporal aggregation by date\n",
        ">+Exercise 3 (answers needed for the MOOC quiz)\n",
        "7. Open and inspect the result in QGIS\n",
        ">+Quiz question (answer needed for the MOOC quiz)\n",
        "\n",
        "**Data needed:**\n",
        "\n",
        "For the exercises of the [MOOC Python for geospatial analyses using WaPOR data](https://ocw.un-ihe.org/course/view.php?id=272) you can use the following data which you can download using the [Download_WaPORv3_Data Notebook](https://github.com/wateraccounting/WaPORMOOC/blob/main/1_WaPOR_download_colab/Download_WaPORv3_Data.ipynb):\n",
        "1. Area: Wad Helal in the Gezira Irrigation Scheme (you can find the \\\"Wad_Helal_projected.geojson\\\" file in the data folder of [WaPORMOOC](https://github.com/wateraccounting/WaPORMOOC/tree/main/data)).\n",
        "2. Spatial resolution: Level 3\n",
        "3. Temporal resolution: dekadal\n",
        "4. Start date: 2022-10-01\n",
        "5. End date: 2023-04-30\n"
      ],
      "metadata": {
        "id": "KfyYPA9XRluP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1**\n"
      ],
      "metadata": {
        "id": "vKuf17_1sfgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rioxarray --quiet"
      ],
      "metadata": {
        "id": "V7_8Eec-sh6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import datetime\n",
        "import xarray as xr\n",
        "import rioxarray as rio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "leom989Lsmck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2 - Create a .zip file/Upload an existing .zip files**\n",
        "We will now upload a .zip file containing a series of .tif files to our session: wapor_data.zip.\n",
        "   \n",
        "Execute the command below and navigate to where you have saved the .zip file from Topic3_N01 in your local drive.\n",
        "\n",
        "(If you are uploading your own .tif files, you can first create a .zip archive from these files, you may need to install compression software such as 7zip (https://www.7-zip.org/) or WinRAR (https://www.win-rar.com/) to perform this operation.)"
      ],
      "metadata": {
        "id": "D0Q2vhKSSnax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To upload file.\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "Kmk8F9TJTKqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3 - Unzip files**\n",
        "Unzip the file you have uploaded.\n",
        "The command is:\n",
        " !unzip 'file_path.zip' -d 'folder_to_unzip_path'\n",
        "Replace the file name in the cell below with the name of your own file. You can find the path to your file by clicking on the 3 dots next to the file name in your file explorer to the left and selecting *Copy path*. (If you do not see your files to the left, click on the folder icon to expand the Files panel)\n"
      ],
      "metadata": {
        "id": "S2WNbvDpT9hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the uploaded zipfile\n",
        "!unzip '/content/data.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "MOMfTjI-UIBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4 - Opening and inspecting one .tif file**\n",
        "Before performing any operations let us open one of our tif files using the rioxarray package."
      ],
      "metadata": {
        "id": "HJCsG4aurUMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open first raster from your unzipped files and mask out nan values\n",
        "ds = rio.open_rasterio('/content/data/L3-AETI-D/Wad_Helal_projected.GEZ_L3-AETI-D_NONE_dekad_converted_2022-10-01.tif')\n",
        "ds = ds.where(ds!=ds.attrs['_FillValue'])"
      ],
      "metadata": {
        "id": "GxANcubTvWAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the contents - How many pixels does the raster contain?\n",
        "ds"
      ],
      "metadata": {
        "id": "JdDWtHNjwtbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The values contained are stored as an array with each value representing one pixel.\n",
        "ds.values"
      ],
      "metadata": {
        "id": "m1mAvYOfxC8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can produce a quick map of our data using the plot function\n",
        "ds[0].plot()\n",
        "ax = plt.gca()\n",
        "ax.set_aspect('equal', adjustable='box') #this command will equally space the x and y units"
      ],
      "metadata": {
        "id": "2rpNzr70wzI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the min, max and mean values\n",
        "print(np.nanmin(ds.values), np.nanmax(ds.values), np.nanmean(ds.values))"
      ],
      "metadata": {
        "id": "DOXPVMpSFbgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚡**EXERCISE 1**: write code to find the min, max and mean for the 1st decad of 2023 - note down the the values (rounded to the nearest integer, no decimals), you will need to enter these in the MOOC quiz."
      ],
      "metadata": {
        "id": "w9VmtK7iF6iJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code\n",
        "#Open appropriate raster file with rioxarray and convert the nans\n",
        "\n",
        "\n",
        "# Print the min, max and mean values\n"
      ],
      "metadata": {
        "id": "mGTNUWaFGOSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if you dont convert the nans?"
      ],
      "metadata": {
        "id": "677nUw2-zmNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5 - Seasonal ET from decadal ET**\n",
        "We will now create one raster file which contains the seasonal ET value for our area. For this we simply need to loop through the ET files, and add up the values.   \n",
        "The glob function allows us to list files in a folder matching a specific pattern.\n",
        "For example:  \n",
        "`glob.glob('/content/L3-AETI-D/*.tif')  `  \n",
        "\n",
        "will produce a list of all files with the .tif extension contained in the *L3-AETI-D* folder,\n",
        "while:   \n",
        "`glob.glob('/content/L3-AETI-D/*2022-10*.tif')`\n",
        "\n",
        "will produce a list of all files with the .tif extension which also have the string *202210* in the filename - these will be all of the files from October 2022.\n"
      ],
      "metadata": {
        "id": "1KfuhfI5vPNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to get files from October 2022\n",
        "glob.glob('data/L3-AETI-D/*2022-10*.tif')"
      ],
      "metadata": {
        "id": "ZeuSn7RcGjir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's produce a seasonal file for our whole time period (this will add up all the files in the folder):"
      ],
      "metadata": {
        "id": "t_r8JZkMIaOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, fp in enumerate(glob.glob('data/L3-AETI-D/*.tif')):\n",
        "  fn = os.path.basename(fp)\n",
        "  # OPEN DATA\n",
        "  ds = rio.open_rasterio(fp)\n",
        "  ds = ds.where(ds!=ds.attrs['_FillValue'])\n",
        "  if i == 0:\n",
        "    ds_sum = ds #Initialize sum if we are looking at the first raster\n",
        "  else:\n",
        "    ds_sum += ds #This is the pythonic way of writing ds_sum = ds_sum + ds"
      ],
      "metadata": {
        "id": "1BgbbS-xsUcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_sum.plot()\n",
        "ax = plt.gca()\n",
        "ax.set_aspect('equal', adjustable='box') #this command will equally space the x and y units"
      ],
      "metadata": {
        "id": "w4hgHTvLt4-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we inspect the Attributes of ds_sum, you will notice they no longer correspond to our dataset - a consequence of this is the wrong legend on the map produced above - **we do not have 1200mm/decad of ET!** (note that if you used d_sum = d_sum + ds instead of d_sum += ds, the attributes will simply have been removed in the result).     \n",
        "We can **update the Attributes** below."
      ],
      "metadata": {
        "id": "oRDApwnf1xd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect Attributes to see which ones we will update\n",
        "attrs = ds_sum.attrs\n",
        "attrs"
      ],
      "metadata": {
        "id": "9ijv8DOi1Yzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attrs.update({'start_date': '2022-10-01',\n",
        "              'end_date': '2023-04-30',\n",
        "              'units' : 'mm/season'})\n",
        "del attrs['number_of_days']\n",
        "\n",
        "ds_sum.attrs  = attrs"
      ],
      "metadata": {
        "id": "lr9-f8y088MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_sum.plot()\n",
        "ax = plt.gca()\n",
        "ax.set_aspect('equal', adjustable='box') #this command will equally space the x and y units"
      ],
      "metadata": {
        "id": "ZD9fvPvv8OMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the seasonal sum to a tiff file and download to your local drive\n",
        "ds_sum.rio.to_raster(\"seasonal_et.tif\")\n",
        "files.download(r'/content/seasonal_et.tif')"
      ],
      "metadata": {
        "id": "41I7C8U9Bh8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚡ **EXERCISE 2**: write code to produce the monthly sum of AETI for April 2023, find the min, max and mean - note down the the values (rounded to the nearest integer, no decimals), you will need to enter these in the MOOC quiz!"
      ],
      "metadata": {
        "id": "Iw0jUgMzInyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code\n",
        "#Loop through the correct files to produce a sum for April 2023\n",
        "\n",
        "glob.glob('data/L3-AETI-D/*2023-04*.tif')\n",
        "\n",
        "\n",
        "# Print the min, max and mean values\n",
        "print(np.nanmin(ds.values), np.nanmax(ds.values), np.nanmean(ds.values))\n",
        "\n"
      ],
      "metadata": {
        "id": "Aoq-DoLgDoWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 6** - More detailed temporal aggregation\n",
        "So far we have done aggregation for:\n",
        "1.   all files available\n",
        "2.   all files with an easily recognisable pattern in the file name     \n",
        "\n",
        "We will now learn how to select **only files within a specified time period**, for example between the start and end of season.\n",
        "\n",
        "To do this we will:\n",
        "\n",
        "\n",
        "1.   Obtain a list of all dates for the availabile files as datetime objects\n",
        "2.   Define a start and end date\n",
        "3.   Select only files names for which the date falls between the start and end dates\n",
        "\n",
        "To start we will get a list of the filenames and extract the date from the name: you can observe that the date is contained in the last 10 characters before the file extension.\n"
      ],
      "metadata": {
        "id": "R6rDi2VYHFQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = glob.glob('/content/data/L3-AETI-D/*.tif')\n",
        "fnames"
      ],
      "metadata": {
        "id": "39ilmrhnH0Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how we can isolate the date on one filename:"
      ],
      "metadata": {
        "id": "8QCptzvcFaMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = fnames[0]\n",
        "path1"
      ],
      "metadata": {
        "id": "MuLmcQMMH0Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see a path that looks something like:     \n",
        "\n",
        "`/content/L3-AETI-D/Wad_Helal_projected.GEZ_L3-AETI-D_NONE_dekad_converted_2022-11-21.tif`\n",
        "\n",
        "We want to extract the date, e.g. in this case: '2022-11-21'     \n",
        "Because all of the file names have the same formatting, ending with the date and .tif, we can simply extract the corresponding characters by counting their position from the end of the string:    \n",
        "*   the date is located between the character located 14 positions from the end, and the character located 4 positions from the end.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G0Xt781cIgsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date0 = path1[-14:-4] #[-14:-4] selects characters in the string: starts at the 14th from the end, to 4th from the end\n",
        "print(date0)"
      ],
      "metadata": {
        "id": "cQSD_bfoH0bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is now a *string*. In oder to be able to do operations and comparisons between dates, we need to convert it to a datetime object. We can use the datetime library for this.\n",
        "The datetime.strptime function allows us to go from a string to a datetime object, you can read the documentation [here](https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior)."
      ],
      "metadata": {
        "id": "gGFWH0eaK6ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date0 =  datetime.datetime.strptime(date0, '%Y-%m-%d')\n",
        "date0"
      ],
      "metadata": {
        "id": "uDjGzWLjK5YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now produce a list with all the dates corresponding to our filenames:"
      ],
      "metadata": {
        "id": "3Ibb482AKT8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_dates = []\n",
        "for path0 in fnames:\n",
        "  date0 = datetime.datetime.strptime(path0[-14:-4], '%Y-%m-%d')\n",
        "  file_dates.append(date0)"
      ],
      "metadata": {
        "id": "Zq7uktywH0eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_dates"
      ],
      "metadata": {
        "id": "lIQ_fED4H0ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a list of datetimes. Note that this can be done more succintly with the following command:\n",
        "\n",
        "\n",
        "```\n",
        "[fname[-14:-4] for d in fnames]\n",
        "```\n",
        "\n",
        "We will now define the start and end dates of our season and find the files which are located between these dates:\n",
        "\n"
      ],
      "metadata": {
        "id": "LAE7HJx2Lz4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sos = datetime.datetime(2022,10,1) #start of season date, we use datetime.datetime to convert the year, month, day to a datetime object\n",
        "eos = datetime.datetime(2023,2,28) #end of season date"
      ],
      "metadata": {
        "id": "eDDiULGmH0ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will check which dates from our list fall between the start and end date so we can select only the filenames corresponding to our season.      \n",
        "\n",
        "**note: this is a simplified code and it does not a) Check whether all files from the season are present b) Deal with seasons which do not start and end at the beginning and end of a dekad**"
      ],
      "metadata": {
        "id": "-IcxVJYgOe5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_files = []\n",
        "for i, date in enumerate(file_dates):\n",
        "  if (date >= sos and date < eos):\n",
        "    selected_files.append(fnames[i])\n",
        "selected_files"
      ],
      "metadata": {
        "id": "sqYVbigJO9ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be hard to check if all the files you want are there as they are not sorted, to adjust this you can simply run the following:"
      ],
      "metadata": {
        "id": "3D27-E-lUIR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(selected_files)"
      ],
      "metadata": {
        "id": "5zNuluWVUQwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are interested, another, more elegant way to achieve this result can be done with the following code:\n",
        "```\n",
        "mask = [(ds >= sos and ds < eos) for ds in file_dates]\n",
        "fnames_array = np.array(fnames)\n",
        "selected_files = fnames_array[mask]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "btthLnT6UWlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚡ **EXERCISE 3**: write code to produce the sum of AETI for the period between 21/01/2023 and 10/04/2023, find the min, max and mean - note down the the values (rounded to the nearest integer, no decimals), you will need to enter these in the MOOC quiz!"
      ],
      "metadata": {
        "id": "EqQM9a1WU5rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code\n",
        "#Create the list of files for the season between 21/01/2023 and 10/04/2023\n",
        "sos = datetime.datetime(2023,1,21) #start of season date, we use datetime.datetime to convert the year, month, day to a datetime object\n",
        "eos = datetime.datetime(2023,4,10) #end of season date\n",
        "selected_files = []\n",
        "for i, date in enumerate(file_dates):\n",
        "  if (date >= sos and date < eos):\n",
        "    selected_files.append(fnames[i])\n",
        "selected_files\n",
        "\n",
        "#Compute the sum\n",
        "for i, fp in enumerate(selected_files):\n",
        "  fn = os.path.basename(fp)\n",
        "  # OPEN DATA\n",
        "  ds = rio.open_rasterio(fp)\n",
        "  ds = ds.where(ds!=ds.attrs['_FillValue'])\n",
        "  if i == 0:\n",
        "    ds_sum = ds #Initialize sum if we are looking at the first raster\n",
        "  else:\n",
        "    ds_sum += ds #This is the pythonic way of writing ds_sum = ds_sum + ds\n",
        "\n",
        "\n",
        "# Print the min, max and mean values\n",
        "print(np.nanmin(ds.values), np.nanmax(ds.values), np.nanmean(ds.values))\n"
      ],
      "metadata": {
        "id": "v9B89iUkVKM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 7** - Open your data in QGIS\n",
        "Open the seasonal AETI file you have downloaded in QGIS as well as the shapefile for the area.  \n",
        "Do you notice anything in the extent?  \n",
        "What do you think explains the observation:\n",
        ">a.   The projection is different     \n",
        "b.   The WaPOR Level 3 data does not cover the whole area    \n",
        "c.   The shapefile is wrong    \n",
        "d.   The spatial resolution doesn't match    \n",
        "\n",
        "\n",
        "\n",
        "⚡ You will enter the answer to this question in the MOOC Quiz"
      ],
      "metadata": {
        "id": "WUGQjRs9zphX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You now know how write scripts to aggregate WaPOR data. In the next notebook we will show you more how to run scripts specifically developed for the WaPOR project that do the temporal aggregation and using loops for calculating seasonal data for multiple seasons."
      ],
      "metadata": {
        "id": "PXCuDE5YBBhu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DbfkBOk009Aa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}